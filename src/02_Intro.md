# Introduction

The modern programming landscape is significantly different than it was 20 years ago. When the first C standard was published in 1989, it was safe to assume that the target platform had a single core CPU and some limited amount of memory that could be uniformly accessed. Thanks to Moore's law, roughly every two years, the program would run twice as fast by just updating the hardware. It is thus understandable that this model survived for such a long time. On the software side, abstraction was low too. Because memory was scarce, programs (as well as compilers) had a limit on how complex they could be, thus limiting the need for abstraction.

Since the turn of the 21st century and with the slowdown in Moore's law, these assumptions are becoming less valid by the day. As  platforms get more complex and specialize, the hardware scene has become very heterogeneous. Many computers contain several processors that are spread across multiple sockets. Non-uniform memory access architectures are becoming the standard as machines scale out. Graphical processing units have gone from simple graphical accelerators in commercial computers to high-performance clusters running complex machine learning applications.

Computers are programmed to run increasingly complex tasks and process more memory than ever before. While programmer productivity is important, it is also essential to maximize performance by efficiently utilizing the available hardware resources. Due to the large variety of platforms and associated programming models used to efficiently utilize them, the latter is usually a barrier for the former.

What we want is a programming model that enables the programmer to use all the abstraction he needs while still maximizing hardware utilization. However, every abstraction has a cost. Whether it is collection operations or data structure, every abstraction adds complexity to the program, and that complexity can get in the way of the optimizer.

Staging [@staging] using partial evaluation [@tagless] is a powerful and scalable solution that can be used to automatically strip abstraction from the program being staged and enable generic optimizations to take place, making the resulting program as efficient as possible. Staging alone is not sufficient though. Every modern programming language in use allows users to define loops of arbitrary sizes. It is therefore not possible to inline the entire program into one binary containing no branches nor jumps. There is a minimal necessary complexity in the program that we cannot get rid of. Additionally, if we want to perform distributed computations for example, there are some optimizations that cannot be performed statically but have to be handled by the runtime. Because of these reasons, the compiler needs to be aware of that structure and work around it. Specifically, it must be able to reason about loops and access to structured data.

Delite [@delite] is a multi-staging optimizing compiler architecture that can take high-level programs and generate efficient low-level code that runs on different platforms. The programmer's interface into the framework is made of domain-specific languages (DSL). It provides utilities for DSL authors to express domain specific optimizations, but it also comes with a set of generic transformers for optimizing data structures.

LMS (Lightweight Modular Staging) is the library Delite uses to lift user programs, transform the intermediate representation (IR), and generate code. It provides generic optimizations such as common sub-expression elimination (CSE), dead code elimination (DCE) and loop fusion.

Recent work [@betterfusion] done on LMS updates the loop fusion optimization to get rid of several limitations that it had. However, because of incompatible changes, Delite was not able to profit from those updates and was stuck with the old version.

In this work we present how the new loop fusion works, as well other optimizations present in Delite. We show how these optimizations work together to provide efficient code. We describe how Delite is designed, as well as the changes that had to be made in order to integrate the new semantics of loop fusion. During this redesign we also discovered some unique problems that can occur by working on a staging compiler. We realized that there was a need for better tools associated with this new kind of architecture. We present a few ideas and prototypes that can be used to address this need.
